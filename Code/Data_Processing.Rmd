---
title: "Data Processing"
output: pdf_document
date: "2024-11-05"
---

Before uploading any data sets into RStudio, the relevant csv files were examined in Excel. The two csv files used in this project are from Prof. Malu Jorge at Vanderbilt University. Prof. Malu Jorge identifies one of the longest time periods of consistent data collection by her lab at multiple parks being from 06/28/2021 to 05/19/22. Although nine parks are listed within "cluster.name" of "Wildlife Insights (2021-2022).csv", only three parks cover the majority of the aforementioned time period based on the earliest "start_date" and latest "end_date" for each park in "All Deployments (2019-2022).csv". Those parks include Beaman (06/29/2021-12/31/2022), Bells Bend (06/28/2021-05/19/2022), and Mills Creek(07/20/2021-04/23/2022). To establish a consistent study period for this project in accordance with these three parks, the following time period will be used: 07/20/2021-4/23/2022 (278 days). The following two data sets created from these csv files will have to be filtered to include only the data associated with each of these parks for the chosen time period. 


## Set up, loading packages
```{r}
# Load all relevant packages
library(lubridate)
library(plyr)
library(dplyr)
library(tidyverse)
library(zoo)
library(sf)
library(here)
library(mapview)
```


## Wildlife IDs from Prof. Malu Jorge's Lab at Vanderbilt University

This section includes already identified camera trap data collected within nine local parks in Nashville, TN (including Beaman, Bells Bend, Blue Hole, Edwin Warner, Ellington, Hill Forest, Mill Creek, Percy Warner) from 06/28/2021 to 12/31/2022 (551 days). During this study period, GardePro A3, Browning Strike Force HD ProX, and HAPIMP PH770-8D trail cameras were used; these models have motion detectors and were programmed to have a delay between consecutive triggers.

```{r}
# Read csv into dataframe
id2021to2022 <- read.csv("~/ByndlossLiWilliams/Data/Raw/Wildlife Insights (2021-2022).csv")

# Establish the format of the date and time column
id2021to2022$date.time <- parse_date_time(id2021to2022$date.time, orders = c("m/d/Y H:M"))

# Add columns for date and hour independently
id2021to2022$date<-date(id2021to2022$date.time)
id2021to2022$hour<-hour(id2021to2022$date.time)

BeamanID <- id2021to2022 %>%
  filter(cluster.name == "beaman")

BellsBendID <- id2021to2022 %>%
  filter(cluster.name == "bells.bend")

MillCreekID <- id2021to2022 %>%
  filter(cluster.name == "mill.creek")
```


## Camera Counts Per Day (i.e., sampling effort)

This section includes deployment data on the camera traps set up within nine local parks in Nashville, TN (including Beaman, Bells Bend, Blue Hole, Edwin Warner, Ellington, Hill Forest, Mill Creek, Percy Warner) from 09/21/2019 to 12/31/2022. Lab members placed camera traps at various sites (one camera per site) within the forested areas of these parks.

```{r}
# Set a vector to correspond with the relevant time period
start <- as_date("2021-07-20")
end <- as_date("2022-04-23")
Days <- vector()
Days <- start:end
Days <- as_date(Days)

deployments <- read.csv("~/ByndlossLiWilliams/Data/Raw/All Deployments (2019-2022).csv")

# Adjust the formatting to match the above vector
deployments$start_date <- mdy(deployments$start_date)
deployments$end_date <- mdy(deployments$end_date)

# Filter for each park's deployments
BeamanDeploy <- deployments %>% 
  filter(deployment_id == "beaman-s1-c20-y21" |
           deployment_id == "beaman-s2-c21-y21" |
           deployment_id == "beaman-s3-c22-y21" |
           deployment_id == "beaman-s4-c23-y21" |
           deployment_id == "beaman-s6-c21-y21" |
           deployment_id == "beaman-s10-c18-y22" |
           deployment_id == "beaman-s1-c20-y22" |
           deployment_id == "beaman-s3-c22-y22" |
           deployment_id == "beaman-s4-c23-y22" |
           deployment_id == "beaman-s6-c21-y22" |
           deployment_id == "beaman-s7-c12-y22" |
           deployment_id == "beaman-s8-c3-y22" |
           deployment_id == "beaman-s9-c33-y22")

BellsBendDeploy <- deployments %>%
  filter(deployment_id == "bells.bend-s1-c14-y21" | 
           deployment_id == "bells.bend-s2-c15-y21" |
           deployment_id == "bells.bend-s2-c16-y21" |
           deployment_id == "bells.bend-s3-c16-y21" |
           deployment_id == "bells.bend-s4-c17-y21" |
           deployment_id == "bells.bend-s1-c14-y22" |
           deployment_id == "bells.bend-s2-c15-y22" |
           deployment_id == "bells.bend-s4-c17-y22")

MillCreekDeploy <- deployments %>%
  filter(deployment_id == "mill.creek-s1-c25-y21" | 
           deployment_id == "mill.creek-s1-c2-y21" | 
           deployment_id == "mill.creek-s2-c26-y21" | 
           deployment_id == "mill.creek-s4-c11-y21" | 
           deployment_id == "mill.creek-s5-c3-y21" |
           deployment_id == "mill.creek-s1-c2-y22" |
           deployment_id == "mill.creek-s4-c11-y22" |
           deployment_id == "mill.creek-s5-c3-y22")

# Count the cameras deployed at each part for every day in the time frame
BeamanCameraCount<-vector()
for(i in 1:length(Days)) {
  BeamanCameraCount[i]<-0
    for(z in 1:((nrow(BeamanDeploy)))){
      if(BeamanDeploy[z,2]<=Days[i]&BeamanDeploy[z,3]>=Days[i]){BeamanCameraCount[i]<-BeamanCameraCount[i]+1}
      }
}

BellsBendCameraCount<-vector()
for(i in 1:length(Days)) {
  BellsBendCameraCount[i]<-0
    for(z in 1:((nrow(BellsBendDeploy)))){
      if(BellsBendDeploy[z,2]<=Days[i]&BellsBendDeploy[z,3]>=Days[i]){BellsBendCameraCount[i]<-BellsBendCameraCount[i]+1}
      }
}

MillCreekCameraCount<-vector()
for(i in 1:length(Days)) {
  MillCreekCameraCount[i]<-0
    for(z in 1:((nrow(MillCreekDeploy)))){
      if(MillCreekDeploy[z,2]<=Days[i]&MillCreekDeploy[z,3]>=Days[i]){MillCreekCameraCount[i]<-MillCreekCameraCount[i]+1}
      }
}

# Combine the days and count vectors into a single data frame for each park
BeamanCameraDates <- data.frame(Days, BeamanCameraCount)

BellsBendCameraDates <- data.frame(Days, BellsBendCameraCount)

MillCreekCameraDates <- data.frame(Days, MillCreekCameraCount)
```


## Species Data (filtered, adjusted, and totals)

This section includes 1) filtering by hour, 2) adjusting counts based on sampling effort, and 3) calculating monthly and full period totals in wildlife IDs. To explain, first, the daily wildlife IDs for each species must be filtered by hour at every camera trap separately to remove repeated counts of the same individual(s). Second, to account for sampling effort, the daily wildlife IDs for each species need to be divided by the number of cameras out each day to standardize the data. Third, monthly and full time period totals are calculated to compare data between parks; in this case, totals can be used rather than averages or rolling averages since sampling effort is already accounted for, a consistent time period is already established across parks, and counts are not guaranteed each day.

```{r}
# Create a list of all unique species in each park's data set
BeamanSpeciesList <- unique(BeamanID$species)
BellsBendSpeciesList <- unique(BellsBendID$species)
MillCreekSpeciesList <- unique(MillCreekID$species)

# Establish an empty data frame to store the results and totals
BeamanSpeciesResults <- data.frame()
BeamanSpeciesMonthlyTotals <- data.frame()
BeamanSpeciesFullPeriodTotal <- data.frame(Species = character(), CountAdjusted = numeric())

BellsBendSpeciesResults <- data.frame()
BellsBendSpeciesMonthlyTotals <- data.frame()
BellsBendSpeciesFullPeriodTotal <- data.frame(Species = character(), CountAdjusted = numeric())

MillCreekSpeciesResults <- data.frame()
MillCreekSpeciesMonthlyTotals <- data.frame()
MillCreekSpeciesFullPeriodTotal <- data.frame(Species = character(), CountAdjusted = numeric())

# BEAMAN: Loop through each species in the data set
for (species in BeamanSpeciesList) {
  
  # Filter data for the current species
  BeamanSpeciesData <- BeamanID %>% filter(BeamanID$species == !!species)
  
  # Ensure the date column is in the correct format
  BeamanSpeciesData$date <- as.Date(BeamanSpeciesData$date)
  
  # Prepare for filtering by every hour by...
  # establishing new data frames for camera deployments and filtered data 
  # ensuring only independent records of species data are kept
  BeamanCameras <- levels(as.factor(BeamanSpeciesData$deployment.id))
  BeamanSpeciesData$Independent<-TRUE
  BeamanFiltered <- data.frame()
  
  # Calculate time differences to filter data, 
  # defining a 1-hour interval to identify independent observations
  A <- strptime("2:30", format = "%H:%M")
  B <- strptime("1:30", format = "%H:%M")
  filter <- A - B
  
  # Iterate through each camera and filter records  
  for(i in 1:length(BeamanCameras)){
  group <- BeamanSpeciesData %>% filter(deployment.id == BeamanCameras[i])
  if(nrow(group) > 1){
    for(z in 1:((nrow(group))-1)){
      diff<-group[(z+1),3] - group[z,3]
      if(diff < filter){
        group[(z+1),6]<-FALSE
        }
      }
    }
  BeamanFiltered <- rbind(BeamanFiltered, group)
  }
  BeamanSpeciesData <- BeamanFiltered %>% filter(Independent == TRUE)
    
  # Create a new data frame containing the counts of species each day, accounting for the number of active cameras (i.e., sampling effort)
  # Also, adjust the species counts via dividing by the number of cameras; this accounts for sampling effort
  CountRaw <- vector()
  CountAdjusted<-vector()
  for(i in 1:nrow(BeamanCameraDates)){
    group <- BeamanSpeciesData %>% filter(date == BeamanCameraDates[i,1])
    count <- nrow(group)
    CountRaw[i] <- count
    CountAdjusted[i] <- count / BeamanCameraDates[i,2]
  }
  
  # Create the DailySpecies data frame
  BeamanDailySpecies <- data.frame(BeamanCameraDates$Days,CountRaw,CountAdjusted)
  names(BeamanDailySpecies) <- c("Date", "CountRaw", "CountAdjusted")
  
  # Add a column with the species name
  BeamanDailySpecies$Species <- species
  
  # Store the daily result for the current species
  BeamanSpeciesResults <- rbind(BeamanSpeciesResults, BeamanDailySpecies)
  
    # Create new column and extract month and year before calculating monthly totals
  BeamanDailySpecies$Month <- format(BeamanDailySpecies$Date, "%Y-%m")
  BeamanMonthlyTotals <- aggregate(CountAdjusted ~ Month + Species, data = BeamanDailySpecies, FUN = sum, na.rm = TRUE)
  
  # Store the monthly total results for the current species
  BeamanSpeciesMonthlyTotals <- rbind(BeamanSpeciesMonthlyTotals, BeamanMonthlyTotals)
  
  # Calculate full period total (total for all days)
  BeamanFullPeriodTotal <- sum(BeamanDailySpecies$CountAdjusted, na.rm = TRUE)
  
  # Store the full period total results for the current species
  BeamanSpeciesFullPeriodTotal <- rbind(BeamanSpeciesFullPeriodTotal, data.frame(Species = species, CountAdjusted = BeamanFullPeriodTotal))
}

# BELLSBEND: Loop through each species in the dataset
for (species in BellsBendSpeciesList) {
  
  # Filter data for the current species
  BellsBendSpeciesData <- BellsBendID %>% filter(BellsBendID$species == !!species)
    
  # Ensure the date column is in the correct format
  BellsBendSpeciesData$date <- as.Date(BellsBendSpeciesData$date)
  
  # Filter by every hour
  BellsBendCameras <- levels(as.factor(BellsBendSpeciesData$deployment.id))
  BellsBendSpeciesData$Independent<-TRUE
  BellsBendFiltered <- data.frame()
  
  A <- strptime("2:30", format = "%H:%M")
  B <- strptime("1:30", format = "%H:%M")
  filter <- A - B 
  
  for(i in 1:length(BellsBendCameras)){
  group <- BellsBendSpeciesData %>% filter(deployment.id == BellsBendCameras[i])
  if(nrow(group) > 1){
    for(z in 1:((nrow(group))-1)){
      diff<-group[(z+1),3] - group[z,3]
      if(diff < filter){
        group[(z+1),6]<-FALSE
        }
      }
    }
  BellsBendFiltered <- rbind(BellsBendFiltered, group)
  }
  BellsBendSpeciesData <- BellsBendFiltered %>% filter(Independent == TRUE)
  
  # Create a new data frame containing the counts of species each day
  # Also, adjust the species counts via dividing by the number of cameras; this accounts for sampling effort
  CountRaw <- vector()
  CountAdjusted<-vector()
  for(i in 1:nrow(BellsBendCameraDates)){
    group <- BellsBendSpeciesData %>% filter(date == BellsBendCameraDates[i,1])
    count <- nrow(group)
    CountRaw[i] <- count
    CountAdjusted[i] <- count / BellsBendCameraDates[i,2]
  }
  
  # Create the DailySpecies data frame
  BellsBendDailySpecies <- data.frame(BellsBendCameraDates$Days,CountRaw,CountAdjusted)
  names(BellsBendDailySpecies) <- c("Date", "CountRaw", "CountAdjusted")
  
  # Add a column with the species name
  BellsBendDailySpecies$Species <- species
  
  # Store the daily result for the current species
  BellsBendSpeciesResults <- rbind(BellsBendSpeciesResults, BellsBendDailySpecies)
  
  # Create new column and extract month and year before calculating monthly totals
  BellsBendDailySpecies$Month <- format(BellsBendDailySpecies$Date, "%Y-%m")
  BellsBendMonthlyTotals <- aggregate(CountAdjusted ~ Month + Species, data = BellsBendDailySpecies, FUN = sum, na.rm = TRUE)
  
  # Store the monthly total results for the current species
  BellsBendSpeciesMonthlyTotals <- rbind(BellsBendSpeciesMonthlyTotals, BellsBendMonthlyTotals)
  
  # Calculate full period total (total for all days)
  BellsBendFullPeriodTotal <- sum(BellsBendDailySpecies$CountAdjusted, na.rm = TRUE)
  
  # Store the full period total results for the current species
  BellsBendSpeciesFullPeriodTotal <- rbind(BellsBendSpeciesFullPeriodTotal, data.frame(Species = species, CountAdjusted = BellsBendFullPeriodTotal))
}

# MILLCREEK: Loop through each species in the dataset
for (species in MillCreekSpeciesList) {
  
  # Filter data for the current species
  MillCreekSpeciesData <- MillCreekID %>% filter(MillCreekID$species == !!species)
  
  # Ensure the date column is in the correct format
  MillCreekSpeciesData$date <- as.Date(MillCreekSpeciesData$date)
  
  # Filter by every hour
  MillCreekCameras <- levels(as.factor(MillCreekSpeciesData$deployment.id))
  MillCreekSpeciesData$Independent <- TRUE
  MillCreekFiltered <- data.frame()
  
  A<-strptime("2:30", format = "%H:%M")
  B<-strptime("1:30", format = "%H:%M")
  filter <- A - B
  
  for(i in 1:length(MillCreekCameras)){
  group <- MillCreekSpeciesData %>% filter(deployment.id == MillCreekCameras[i])
  if(nrow(group) > 1){
    for(z in 1:((nrow(group))-1)){
      diff<-group[(z+1),3] - group[z,3]
      if(diff < filter){
        group[(z+1),6]<-FALSE
        }
      }
    }
  MillCreekFiltered <- rbind(MillCreekFiltered, group)
  }
  MillCreekSpeciesData <- MillCreekFiltered %>% filter(Independent == TRUE)
  
  # Create a new data frame containing the counts of species each day
  # Also, adjust the species counts via dividing by the number of cameras; this accounts for sampling effort
  CountRaw <- vector()
  CountAdjusted<-vector()
  for(i in 1:nrow(MillCreekCameraDates)){
    group <- MillCreekSpeciesData %>% filter(date == MillCreekCameraDates[i,1])
    count <- nrow(group)
    CountRaw[i] <- count
    CountAdjusted[i] <- count / MillCreekCameraDates[i,2]
  }

  # Create the DailySpecies data frame
  MillCreekDailySpecies <- data.frame(MillCreekCameraDates$Days,CountRaw,CountAdjusted)
  names(MillCreekDailySpecies) <- c("Date", "CountRaw", "CountAdjusted")
  
  # Add a column with the species name
  MillCreekDailySpecies$Species <- species
  
  # Store the daily result for the current species
  MillCreekSpeciesResults <- rbind(MillCreekSpeciesResults, MillCreekDailySpecies)
    
    # Create new column and extract month and year before calculating monthly totals for each species
  MillCreekDailySpecies$Month <- format(MillCreekDailySpecies$Date, "%Y-%m")
  MillCreekMonthlyTotals <- aggregate(CountAdjusted ~ Month + Species, data = MillCreekDailySpecies, FUN = sum, na.rm = TRUE)
  
  # Store the monthly total results for the current species
  MillCreekSpeciesMonthlyTotals <- rbind(MillCreekSpeciesMonthlyTotals, MillCreekMonthlyTotals)
  
  # Calculate full period total (total for all days)
  MillCreekFullPeriodTotal <- sum(MillCreekDailySpecies$CountAdjusted, na.rm = TRUE)
  
  # Store the full period total results for the current species
  MillCreekSpeciesFullPeriodTotal <- rbind(MillCreekSpeciesFullPeriodTotal, data.frame(Species = species, CountAdjusted = MillCreekFullPeriodTotal))
}

# Add column with park name before combining similar park data frames
BeamanSpeciesResults$ParkName <- "Alvin G. Beaman Park"
BellsBendSpeciesResults$ParkName <- "Bells Bend Park"
MillCreekSpeciesResults$ParkName <- "Mill Creek Park"

BeamanSpeciesMonthlyTotals$ParkName <- "Alvin G. Beaman Park"
BellsBendSpeciesMonthlyTotals$ParkName <- "Bells Bend Park"
MillCreekSpeciesMonthlyTotals$ParkName <- "Mill Creek Park"

BeamanSpeciesFullPeriodTotal$ParkName <- "Alvin G. Beaman Park"
BellsBendSpeciesFullPeriodTotal$ParkName <- "Bells Bend Park"
MillCreekSpeciesFullPeriodTotal$ParkName <- "Mill Creek Park"

# Combine the similar park data sets
CombinedSpeciesResults <- bind_rows(BeamanSpeciesResults,
                                    BellsBendSpeciesResults,
                                    MillCreekSpeciesResults)
CombinedMonthlyTotals <- bind_rows(BeamanSpeciesMonthlyTotals,
                                   BellsBendSpeciesMonthlyTotals,
                                   MillCreekSpeciesMonthlyTotals)
CombinedFullPeriodTotals <- bind_rows(BeamanSpeciesFullPeriodTotal,
                                      BellsBendSpeciesFullPeriodTotal,
                                      MillCreekSpeciesFullPeriodTotal)
```


## Spatial Data

This section includes spatial data on parks in Nashville, TN (retrieved from Nashville Open Data at the following link: https://datanashvillegov-nashville.hub.arcgis.com/datasets/13c1aa2bafdd43f4b3cd132e7256a172_0/explore?location=36.167341%2C-86.763938%2C9.17). The csv version of this shapefile was examined in Excel prior to uploading to RStudio. From that initial examination, it became clear that numerous similarities exist between these three parks (e.g., being open daily, not allowing horseback riding, and not having any sports fields or courts available). Still, there are certain attributes that make each of these three parks unique from one another. To briefly explain, Beaman (a regional park established in 1996) is the largest of the three parks at 2170.89186 acres, open dawn to 11pm, and more restrictive with no walking or jogging on certain trails. Bells Bend (a regional park established in 2007) is an intermediate size at 809.59 acres, has a more restrictive schedule being open dawn to dusk, and allows more activities, including mountain biking, camping, and fishing. Lastly, Mill Creek (a community park established in 2013) is the smallest of the three parks at 85.62 acres, open dawn to 11pm, and has no hiking trails.

```{r}
# Read the shapefile into a  dataframe
parks <- st_read('~/ByndlossLiWilliams/Data/Raw/Parks_Properties.shp')

# Check for unique park names to ensure correct name for upcoming filter
unique(parks$Name)

# Filter for each park
BeamanAttributes <- parks %>%
  filter(Name == "Alvin G. Beaman Park")

BellsBendAttributes <- parks %>%
  filter(Name == "Bells Bend Park")

MillCreekAttributes <- parks %>%
  filter(Name == "Mill Creek Park")

# Check to ensure the data frames are correct by mapping them
mapView(BeamanAttributes) + mapView(BellsBendAttributes) + mapView(MillCreekAttributes)

# Combine data frames for parks of interest
CombinedParkAttributes <- rbind(BeamanAttributes, 
                                BellsBendAttributes, 
                                MillCreekAttributes)
```


## Merging Data Frames (species and spatial data)

This section merges the daily and monthly species data frames with the park attributes data frame. These merges are completed in preparation for a series of two-sample t-tests, which will appear in the data analysis rmd file. By selecting three unique park characteristics, each park gets the opportunity to be compared against the other two parks. To go into more detail, Mill Creek (being classified as a community park) will be compared to the regional parks; Beaman (being substantially larger) will be compared to the parks that are less than 1000 acres; and Bells Bend (allowing more disruptive activities, i.e., mountain biking, camping, and fishing) will be compared to parks with more restrictive rules for activities. Still, there are other characteristics that distinguish these parks from one another as mentioned in the previous section, but park classification, size, and disruptive activities are expected to have the largest influences on species activity. Notably, while park classification takes into account the size of the park, it also relates to the purpose of the park.

```{r}
# Rename column within combined data frame
# Filter rows of interest before merging;
# Notably, chosen rows contain the unique differences between parks 
# that are suspected of having the most highest influence on species activity
FilteredParkAttributes <- CombinedParkAttributes %>%
  dplyr::rename(ParkName = Name) %>%
  dplyr::rename(Classification = Classifica) %>%
  mutate(Size = ifelse(Acres > 1000, ">1000ac", "<1000ac")) %>%
   mutate(DisruptiveActivities = ifelse(MountainBi == "Yes" & 
                                          Camping == "Yes" & 
                                          Fishing == "Yes", 
                                        "Yes", "No")) %>%
  select(ParkName, Classification, Size, DisruptiveActivities)

# Merged daily and monthly species count with spatial data
# Removed geometry since it is not necessary for intended ANOVAs
DailyMerge <- merge(CombinedSpeciesResults, 
                    FilteredParkAttributes, 
                    by = "ParkName")  %>%
  select(-geometry)

MonthlyMerge <- merge(CombinedMonthlyTotals, 
                      FilteredParkAttributes, 
                      by = "ParkName") %>%
  select(-geometry)
```


## Save Processed Data

This section simply saves the final processed data frames into the "Processed" folder, which is within the "Data" folder of this project.

```{r}
# Save and rename the final processed data
write.csv(CombinedSpeciesResults, 
          row.names = FALSE, 
          file = "./Data/Processed/Daily_Species_Counts.csv")

write.csv(CombinedMonthlyTotals, 
          row.names = FALSE, 
          file = "./Data/Processed/Monthly_Species_Counts.csv")

write.csv(CombinedFullPeriodTotals, 
          row.names = FALSE, 
          file = "./Data/Processed/Full_Period_Species_Counts.csv")

st_write(CombinedParkAttributes,
          "./Data/Processed/Park_Attributes.shp")

write.csv(DailyMerge, 
          row.names = FALSE, 
          file = "./Data/Processed/Daily_Merge.csv")

write.csv(MonthlyMerge, 
          row.names = FALSE, 
          file = "./Data/Processed/Monthly_Merge.csv")
```

